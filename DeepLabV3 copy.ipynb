{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os  \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, data_type='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform  \n",
    "        self.image_dir = f'{root_dir}/{data_type}/images/'\n",
    "        self.mask_dir = f'{root_dir}/{data_type}/masks/'\n",
    "        self.image_paths = sorted(os.listdir(self.image_dir))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #shuffle_data(self.image_paths)\n",
    "        image_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        mask_path = os.path.join(self.mask_dir, self.image_paths[idx])\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts PIL Image to PyTorch tensor\n",
    "])\n",
    "    \n",
    "\n",
    "train_dataset = CustomDataset(root_dir='Dataset', data_type='train', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir='Dataset', data_type='val', transform=transform)\n",
    "test_dataset = CustomDataset(root_dir='Dataset', data_type='test', transform=transform)\n",
    "\n",
    "\n",
    "#convert targets to tragers.\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: 10\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(train_dataset[0][1])) # 2 classes: [0, 1]\n",
    "print(f\"Unique classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cipher73/.local/lib/python3.10/site-packages/segmentation_models_pytorch/base/modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m runner \u001b[39m=\u001b[39m SupervisedRunner()\n\u001b[1;32m     32\u001b[0m \u001b[39m# model training\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m runner\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     34\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     35\u001b[0m     criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m     36\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     37\u001b[0m     loaders\u001b[39m=\u001b[39;49mloaders,\n\u001b[1;32m     38\u001b[0m     logdir\u001b[39m=\u001b[39;49mlogdir,\n\u001b[1;32m     39\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     40\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/runners/runner.py:377\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self, loaders, model, engine, criterion, optimizer, scheduler, callbacks, loggers, seed, hparams, num_epochs, logdir, resume, valid_loader, valid_metric, minimize_valid_metric, verbose, timeit, check, overfit, profile, load_best_on_end, cpu, fp16, ddp)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_best_on_end \u001b[39m=\u001b[39m load_best_on_end\n\u001b[1;32m    376\u001b[0m \u001b[39m# run\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:422\u001b[0m, in \u001b[0;36mIRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception \u001b[39m=\u001b[39m ex\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_exception\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    423\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:365\u001b[0m, in \u001b[0;36mIRunner._run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[39mgetattr\u001b[39m(callback, event)(\u001b[39mself\u001b[39m)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m is_str_intersections(event, (\u001b[39m\"\u001b[39m\u001b[39m_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_exception\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m--> 365\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, event)(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:357\u001b[0m, in \u001b[0;36mIRunner.on_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_exception\u001b[39m(\u001b[39mself\u001b[39m, runner: \u001b[39m\"\u001b[39m\u001b[39mIRunner\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    356\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Event handler.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:419\u001b[0m, in \u001b[0;36mIRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs the experiment.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39m    self, `IRunner` instance after the experiment\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run()\n\u001b[1;32m    420\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception \u001b[39m=\u001b[39m ex\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:410\u001b[0m, in \u001b[0;36mIRunner._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_engine()\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine\u001b[39m.\u001b[39;49mspawn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_local)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/engine.py:59\u001b[0m, in \u001b[0;36mEngine.spawn\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspawn\u001b[39m(\u001b[39mself\u001b[39m, fn: Callable, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Spawns processes with specified ``fn`` and ``args``/``kwargs``.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m        wrapped function (if needed).\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:405\u001b[0m, in \u001b[0;36mIRunner._run_local\u001b[0;34m(self, local_rank, world_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_rank, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_world_size \u001b[39m=\u001b[39m local_rank, world_size\n\u001b[1;32m    404\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_experiment_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 405\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_experiment()\n\u001b[1;32m    406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_experiment_end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:399\u001b[0m, in \u001b[0;36mIRunner._run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_epoch()\n\u001b[1;32m    400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:391\u001b[0m, in \u001b[0;36mIRunner._run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaders\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    390\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_loader_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_loader()\n\u001b[1;32m    392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_loader_end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:386\u001b[0m, in \u001b[0;36mIRunner._run_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_event(\u001b[39m\"\u001b[39m\u001b[39mon_batch_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    385\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_batch(batch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch)\n\u001b[0;32m--> 386\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_batch_end\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/core/runner.py:363\u001b[0m, in \u001b[0;36mIRunner._run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, event)(\u001b[39mself\u001b[39m)\n\u001b[1;32m    362\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mgetattr\u001b[39;49m(callback, event)(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m is_str_intersections(event, (\u001b[39m\"\u001b[39m\u001b[39m_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_exception\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    365\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, event)(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/callbacks/metric.py:212\u001b[0m, in \u001b[0;36mBatchMetricCallback.on_batch_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"On batch end action: update metric with new batch data\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39mand log it's value if necessary\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    runner: current runner\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m metrics_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(runner\u001b[39m=\u001b[39mrunner)\n\u001b[0;32m--> 212\u001b[0m metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_metric(metrics_inputs)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_on_batch:\n\u001b[1;32m    214\u001b[0m     runner\u001b[39m.\u001b[39mbatch_metrics\u001b[39m.\u001b[39mupdate(metrics)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/callbacks/metric.py:155\u001b[0m, in \u001b[0;36m_MetricCallback._update_value_metric\u001b[0;34m(self, value_inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_value_metric\u001b[39m(\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m, value_inputs: Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]\n\u001b[1;32m    145\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m    146\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m    Update metric in value input case\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        result of metric update: None or metric values\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_update_method(\u001b[39m*\u001b[39;49mvalue_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/metrics/_functional_metric.py:103\u001b[0m, in \u001b[0;36mFunctionalBatchMetric.update_key_value\u001b[0;34m(self, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_key_value\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m, batch_size: \u001b[39mint\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m     92\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m    Calculate metric and update average metric\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m        Dict with one element-custom metric\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(batch_size, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: value}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/metrics/_functional_metric.py:85\u001b[0m, in \u001b[0;36mFunctionalBatchMetric.update\u001b[0;34m(self, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, batch_size: \u001b[39mint\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m    Calculate metric and update average metric\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m        custom metric\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditive_metric\u001b[39m.\u001b[39mupdate(\u001b[39mfloat\u001b[39m(value), batch_size)\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catalyst/callbacks/criterion.py:47\u001b[0m, in \u001b[0;36mCriterionCallback._metric_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_metric_fn\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/segmentation_models_pytorch/losses/dice.py:94\u001b[0m, in \u001b[0;36mDiceLoss.forward\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     92\u001b[0m         y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m mask\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)  \u001b[39m# N, C, H*W\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         y_true \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mone_hot(y_true, num_classes)  \u001b[39m# N,H*W -> N,H*W, C\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# N, C, H*W\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m MULTILABEL_MODE:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "model = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights='imagenet', decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=num_classes, activation=\"softmax\", aux_params=None)  # num_classes is the number of segmentation classes\n",
    "encoder_name = 'resnet34'\n",
    "num_epochs = 10\n",
    "loaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": val_loader\n",
    "}\n",
    "\n",
    "# model, criterion, optimizer\n",
    "# model = # already defined\n",
    "criterion = smp.losses.DiceLoss(mode='multiclass')\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.decoder.parameters(), 'lr': 1e-4}, \n",
    "    \n",
    "    # decrease lr for encoder in order not to permute \n",
    "    # pre-trained weights with large gradients on training start\n",
    "    {'params': model.encoder.parameters(), 'lr': 1e-6},  \n",
    "])\n",
    "scheduler = None\n",
    "\n",
    "# @TODO: add metrics support \n",
    "# (catalyst expects logits, rather than sigmoid outputs)\n",
    "# metrics = [\n",
    "#     smp.utils.metrics.IoUMetric(eps=1.),\n",
    "#     smp.utils.metrics.FscoreMetric(eps=1.),\n",
    "# ]\n",
    "\n",
    "logdir = \"./logs/segmentation_notebook\"\n",
    "# model runner\n",
    "runner = SupervisedRunner()\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl.utils import UtilsFactory\n",
    "# you can use plotly and tensorboard to plot metrics inside jupyter\n",
    "# by default it only plots loss\n",
    "# not sure if it correctly works in Colab\n",
    "UtilsFactory.plot_metrics(logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on a test batch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(test_loader))  # Get a test batch\n",
    "    test_inputs, _ = test_batch  # Extract input images\n",
    "    predictions = model(test_inputs)  # Perform inference on the test batch\n",
    "\n",
    "# Visualize the output masks\n",
    "# Assuming 'predictions' and 'targets' are tensors\n",
    "batch_index = 0  # Index of the batch you want to visualize\n",
    "num_masks_to_visualize = 3  # Number of masks to visualize\n",
    "\n",
    "predicted_masks = predictions[batch_index].cpu().numpy()  # Convert tensor to NumPy array\n",
    "\n",
    "for i in range(num_masks_to_visualize):\n",
    "    image, mask = test_dataset[i]  # get some sample\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot predicted mask\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(predicted_masks[i], cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    \n",
    "    # Plot target mask\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask.permute(1, 2, 0))\n",
    "    plt.title('Target Mask')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
